\input{configuration}

\title{Lecture 18 --- Concurrency \& Synchronization in POSIX }

\author{Jeff Zarnett \\ \small \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}


\begin{frame}
\frametitle{Concurrency with pthreads}

Earlier we saw pthreads \& how we can use them: multithreaded programs. 

There are, accordingly, pthread routines for working with mutual exclusion.

\end{frame}


\begin{frame}
\frametitle{Mutexes and pthreads}

\texttt{pthread\_mutex\_init}: used to create a new mutex variable and returns it, with type \texttt{pthread\_mutex\_t}. 

It takes an optional parameter, the attributes (the details of which are not important at the moment, but relate mostly to priorities).

We can initialize it using null, or:

\texttt{pthread\_mutex\_t mymutex = PTHREAD\_MUTEX\_INITIALIZER;} 

\end{frame}

\begin{frame}
\frametitle{Mutexes and pthreads}

When created, by default, the mutex is unlocked. 

There are three methods related to using the mutex; two to lock it and one to unlock it, all of which take as a parameter the mutex to (un)lock. 

The unlock method, \texttt{pthread\_mutex\_unlock} is self-explanatory. 

The two kinds of lock are \texttt{pthread\_mutex\_lock}, which is blocking, and \texttt{pthread\_mutex\_trylock}, which is nonblocking. 

Attempting to unlock a mutex that is not currently locked is an error.

Also an error if one thread attempts to unlock a mutex owned by another.

\end{frame}

\begin{frame}
\frametitle{Destroying the Mutex}

To destroy a mutex, there is a method \texttt{pthread\_mutex\_destroy}. 

It cleans up a mutex and should be used when finished with it.

If attributes were created with \texttt{pthread\_mutexattr\_init} they should be destroyed with \texttt{pthread\_mutexattr\_destroy}.

\end{frame}

\begin{frame}
\frametitle{Destruction Aborted}

An attempt to destroy the mutex may fail if the mutex is currently locked. 

The specification says that destroying an unlocked mutex is okay, but attempting to destroy a locked one results in undefined behaviour. 

Undefined behaviour is, in the words of the internet, the worst thing ever.

It means code might work some of the time or on some systems, but not others. 

Or it could work fine for a while and then break suddenly later.
\end{frame}

\begin{frame}
\frametitle{Condition Variables}

Condition variables are another way to achieve synchronization.

A condition variable allows synchronization based on the value of the data. 

Instead of locking a mutex, checking a variable, and then unlocking the mutex, we could achieve the same goal without constantly polling. 

We can think of condition variables as ``events'' that occur.

\end{frame}

\begin{frame}
\frametitle{Condition Variables: Events}

An event is similar to, but slightly different from, a counting semaphore. 

When an event occurs we can:\\
\quad Signal either one thread waiting for that event to occur, or\\
\quad Broadcast (signal) to all threads waiting for the event. 

If a thread signals a condition variable that an event has occurred, but no thread is waiting for that event, the event is ``lost''. 

\end{frame}

\begin{frame}
\frametitle{Condition Variables and pthreads}

To create a \texttt{pthread\_cond\_t} (condition variable type), the function is \texttt{pthread\_cond\_init}.

To destroy them, \texttt{pthread\_cond\_destroy}. 

As before, we can initialize them with attributes, and there are functions to create and destroy the attribute structures, too. 

\end{frame}

\begin{frame}
\frametitle{Condition Variables as a Building Block}

Condition variables are a building block and must be paired with a mutex. 

To wait on a condition variable, the function \texttt{pthread\_cond\_wait} takes two parameters: the condition variable and the mutex. 

This routine should be called only while the mutex is locked.

\end{frame}

\begin{frame}
\frametitle{Condition Variables as a Building Block}

It will automatically release the mutex while it waits for the condition. 

When the condition is true then the mutex will be automatically locked again so the thread may proceed. 

The programmer then unlocks the mutex when the thread is finished with it. 

\end{frame}

\begin{frame}
\frametitle{Condition Variables}

There is \texttt{pthread\_cond\_signal} that signals a provided condition variable. 

There is also \texttt{pthread\_cond\_broadcast} that signals all threads waiting. 

It is (almost always) a logical error to signal or broadcast on a condition variable before some thread is waiting on it.

\end{frame}

\begin{frame}
\frametitle{Condition Variable Example}

[This code is too big for slides; see notes.]

\end{frame}

\begin{frame}
\frametitle{Monitors}

A condition variable can be used to create a \alert{monitor}.

Analogy: in object-oriented programming we package up data and functions inside a class to make errors less likely and to improve the design. 

When we use a monitor we are packaging up the shared data and operations on that data to avoid problems of synchronization and concurrency.

\end{frame}

\begin{frame}
\frametitle{Monitors}

Goal: make it so that programmers do not need to code the synchronization part directly, making it less likely a programmer makes an error.

\begin{center}
\includegraphics[width=0.65\textwidth]{images/sync-monitor.png}
\end{center}

\end{frame}

\begin{frame}
\frametitle{Monitor Example}


Suppose there are processes $P$ and $Q$ and a condition variable $x$. 

If $P$ signals on $x$ when $Q$ is waiting, there are two things we can do:\\
\quad \alert{signal-and-wait} or \alert{signal-and-continue}. 

Signal-and-continue seems logical, in one sense: $P$ is already running, so why do the extra work to switch? 

On the other hand, by the time $P$ exits the monitor on its own, the condition $Q$ was waiting for might no longer be true.

Some programming languages opt for a compromise: after signalling, $P$ must immediately leave the monitor.

\end{frame}

\begin{frame}
\frametitle{Monitors and \texttt{synchronized}}

The idea of monitors should be familiar to you if you have used the Java \texttt{synchronized} keyword. 

In Java we can declare a method to be \texttt{synchronized}.\\
\quad Then there is a lock created around that method. 

Only one thread can be inside that method at a time.

If a second would like to call that method on the same instance, it will be placed in the entry set for the lock.

\end{frame}

\begin{frame}[fragile]
\frametitle{Java Synchronization}


In Java we can make a method \texttt{synchronized} or define a block as synchronized:

\begin{verbatim}
public synchronized void doSomething() {
    // Synchronized area
}
\end{verbatim}



\begin{verbatim}
public void exampleMethod() {
    synchronized( object ) { // Lock must be acquired to enter
           // Critical section 
    } // Lock is automatically released.
}
\end{verbatim}


\end{frame}

\begin{frame}
\frametitle{UNIX Concurrency Mechanisms}

UNIX also has semaphores (not just in the pthreads). 

The semaphore in UNIX is general, and maintains a few pieces of extra data:

\begin{itemize}
    \item The value of the semaphore.
    \item Process ID of the last process to operate it.
    \item Number of processes waiting on a value greater than the current value.
    \item Number of processes waiting for the value to be 0.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{UNIX Semaphores}

UNIX semaphores are technically created in sets of one or more. 

It is possible to manage semaphores en masse with a system call (\texttt{semctl}).

This then performs the requested operation on all of the semaphores in the set. 

There is also a \texttt{sem\_op} system call that takes as an argument, a list of semaphore operations, each defined on one of the semaphores in the set. 

When \texttt{sem\_op} is used, the indicated operations are performed one at a time.

\end{frame}

\begin{frame}
\frametitle{UNIX \texttt{sem\_op}}

The meanings of \texttt{sem\_op} can be:
\begin{itemize}
    \item \texttt{sem\_op} positive
    \item \texttt{sem\_op} 0
    \item \texttt{sem\_op} negative and its absolute value $\leq$ to the semaphore value
    \item \texttt{sem\_op} negative and its absolute value $>$ the semaphore value
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Linux Kernel Concurrency Mechanisms}

The Linux kernel provides operations that are guaranteed to execute atomically, to avoid simple race conditions.

Uniprocessor system: CPU can't be interrupted until the operation is finished.

Multiprocessor system: the variable is locked until the operation is finished.

\end{frame}

\begin{frame}
\frametitle{Linux Kernel Concurrency Mechanisms}

There are two types of atomic operations:\\
\quad Those that operate on integers; and\\
\quad Those that operate on a single bit in a bitmap. 

On some architectures, the atomic operations are translated into uninterruptible assembly instructions.

On others, the memory bus is locked to ensure the operation is atomic.

\end{frame}


\begin{frame}
\frametitle{Linux Kernel Concurrency Mechanisms}

Rather than just using an integer for atomic integer operations, there is a defined type \texttt{atomic\_t}. 

This ensures that only atomic operations can be used on this data type and that atomic operations can only be used on that data type. 

This prevents programming errors and hides architecture-specific implementation details.


\end{frame}

\begin{frame}
\frametitle{Linux Atomic Operations}

{\scriptsize
\begin{center}
\begin{tabular}{l|l}
	\textbf{Function} & \textbf{Description}\\\hline

	\texttt{ATOMIC\_INIT( int i )} & At declaration, initialize an \texttt{atomic\_t} to \texttt{i}\\\hline

\texttt{int atomic\_read( atomic\_t *v )} &  Read the integer value of \texttt{v}\\\hline

\texttt{void atomic\_set( atomic\_t *v, int i )} & Set \texttt{v} equal to \texttt{i}\\\hline

\texttt{void atomic\_add( int i, atomic\_t *v )} & Add \texttt{i} to \texttt{v}\\\hline

\texttt{void atomic\_sub( int i, atomic\_t *v )} & Subtract \texttt{i} from \texttt{v}\\\hline

\texttt{void atomic\_inc( atomic\_t *v )} & Add 1 to \texttt{v}\\\hline

\texttt{void atomic\_dec( atomic\_t *v )} & Subtract 1 from \texttt{v}\\\hline

\texttt{int atomic\_sub\_and\_test( int i, atomic\_t *v )} & Subtract \texttt{i} from \texttt{v}; return true if 0; otherwise false\\\hline

\texttt{int atomic\_add\_negative( int i, atomic\_t *v )} & Add \texttt{i} to \texttt{v}; return true if negative; otherwise false\\\hline

\texttt{int atomic\_dec\_and\_test( atomic\_t *v )} & Decrement \texttt{v} by 1; return true if 0; otherwise false\\\hline

\texttt{int atomic\_inc\_and\_test( atomic\_t *v )} & Increment \texttt{v} by 1; return true if 0; otherwise false\\ \hline\hline

\texttt{void set\_bit( int n, void *addr )} &  Set the $n^{th}$ bit starting from \texttt{addr}\\\hline

\texttt{void clear\_bit( int n, void *addr )} &  Clear the $n^{th}$ bit starting from \texttt{addr}\\\hline

\texttt{void change\_bit( int n, void *addr )} &  Flip the value of the $n^{th}$ bit starting from \texttt{addr}\\\hline

\texttt{int test\_and\_set\_bit( int n, void *addr )} &  Set $n^{th}$ bit starting from \texttt{addr}; return previous value\\\hline

\texttt{int test\_and\_clear\_bit( int n, void *addr )} &  Clear $n^{th}$ bit starting from \texttt{addr}; return previous value\\\hline

\texttt{int test\_and\_change\_bit( int n, void *addr )} &  Flip $n^{th}$ bit starting from \texttt{addr}; return previous value\\\hline

\texttt{int test\_bit( int n, void *addr )} &  Return value of $n^{th}$ bit starting from \texttt{addr}\\\hline

\end{tabular}
\end{center}
}

\end{frame}

\begin{frame}
\frametitle{Linux Spinlocks}

Another technique for protecting a critical section in Linux is the \alert{spinlock}. 

This is a handy way to implement constant checking to acquire a lock.

Unlike semaphores where the process is blocked if it fails to acquire the lock, a thread will constantly try to acquire the lock. 

The implementation is an integer that is checked by a thread.

\end{frame}

\begin{frame}[fragile]
\frametitle{Linux Spinlocks}

This is very inefficient; it would be better to let another thread execute.

Except where the amount of time waiting on the lock is less than it would take to block the process, switch to another, and unblock it when the value changes.

\begin{verbatim}
spin_lock( &lock )
    /* Critical Section */
spin_unlock( & lock )
\end{verbatim}

\end{frame}

\begin{frame}
\frametitle{Linux Reader-Writer Spinlock}

There are \alert{reader-writer-spinlocks}. 

Allow multiple readers but give exclusive access to a writer. 

This is implemented as a 24-bit reader counter and an unlock flag:
\begin{center}
\begin{tabular}{l|l|l}
	\textbf{Counter} & \textbf{Flag} & \textbf{Interpretation}\\\hline
	0 & 1 & The spinlock is released and available. \\
	0 & 0 & The spinlock has been acquired for writing.\\
	$n$ ($n > 0$) & 0 & The spin lock has been acquired for reading by $n$ threads.\\
	$n$ ($n > 0$) & 1 & Invalid state.\\
\end{tabular}
\end{center}

\end{frame}

\end{document}

